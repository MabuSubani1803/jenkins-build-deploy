{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Gas Turbine.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1A8ZkiN7TN3zzBXQ5fQJSITt_dqZzCaMr\n",
    "\"\"\"\n",
    "\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Importing Dataset\n",
    "turbine=pd.read_csv(\"/content/gas_turbines.csv\")\n",
    "turbine\n",
    "\n",
    "\"\"\"Data Exploration\"\"\"\n",
    "\n",
    "turbine.isnull().sum()\n",
    "\n",
    "\"\"\"Descriptive Analysis\"\"\"\n",
    "\n",
    "turbine.shape\n",
    "\n",
    "#Checking the data types\n",
    "turbine.dtypes\n",
    "\n",
    "#Unique values for every feature\n",
    "turbine.nunique()\n",
    "\n",
    "turbine.info()\n",
    "\n",
    "turbine.describe()\n",
    "\n",
    "turbine.duplicated().sum()\n",
    "\n",
    "numerical_features = turbine.describe(include=[\"int64\",\"float64\"]).columns\n",
    "numerical_features\n",
    "\n",
    "\"\"\"Data Visualization\"\"\"\n",
    "\n",
    "#Importing Libraries seaborn and matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Having a look at the correlation matrix\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "mask = np.zeros_like(turbine.corr(), dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(data=turbine.corr(), cmap=\"jet\", annot=True,linewidths=1, linecolor='white',mask=mask)\n",
    "\n",
    "numerical_features=[feature for feature in turbine.columns if turbine[feature].dtypes != 'O']\n",
    "for feat in numerical_features:\n",
    "    skew = turbine[feat].skew()\n",
    "    sns.distplot(turbine[feat], kde= False, label='Skew = %.3f' %(skew), bins=30)\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "#boxplot\n",
    "ot=turbine.copy()\n",
    "fig, axes=plt.subplots(11,1,figsize=(14,16),sharex=False,sharey=False)\n",
    "sns.boxplot(x='AT',data=ot,palette='crest',ax=axes[0])\n",
    "sns.boxplot(x='AP',data=ot,palette='crest',ax=axes[1])\n",
    "sns.boxplot(x='AH',data=ot,palette='crest',ax=axes[2])\n",
    "sns.boxplot(x='AFDP',data=ot,palette='crest',ax=axes[3])\n",
    "sns.boxplot(x='GTEP',data=ot,palette='crest',ax=axes[4])\n",
    "sns.boxplot(x='TIT',data=ot,palette='crest',ax=axes[5])\n",
    "sns.boxplot(x='TAT',data=ot,palette='crest',ax=axes[6])\n",
    "sns.boxplot(x='TEY',data=ot,palette='crest',ax=axes[7])\n",
    "sns.boxplot(x='CDP',data=ot,palette='crest',ax=axes[8])\n",
    "sns.boxplot(x='CO',data=ot,palette='crest',ax=axes[9])\n",
    "sns.boxplot(x='NOX',data=ot,palette='crest',ax=axes[10])\n",
    "plt.tight_layout(pad=2.0)\n",
    "\n",
    "\"\"\"Multivariate Analysis\"\"\"\n",
    "\n",
    "for i in turbine.columns:\n",
    "    if i!=\"TEY\":\n",
    "        plt.scatter(np.log(turbine[i]), np.log(turbine['TEY']))\n",
    "        plt.title(i+ ' vs TEY')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "x = turbine.drop('TEY', axis=1)\n",
    "y = turbine[[\"TEY\"]]\n",
    "\n",
    "\"\"\"Feature Selection Technique\"\"\"\n",
    "\n",
    "model_data = turbine[['CDP', 'GTEP','TIT', 'TAT', 'AFDP', 'CO', 'AT',\"TEY\"]]\n",
    "model_data.head()\n",
    "\n",
    "\"\"\"Data Pre-Processing\"\"\"\n",
    "\n",
    "continuous_feature=[feature for feature in model_data.columns if model_data[feature].dtype!='O']\n",
    "print('Continuous Feature Count {}'.format(len(continuous_feature)))\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df_scaled = model_data.copy()\n",
    "features = df_scaled\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_scaler= scaler.fit_transform(features.values)\n",
    "df_scaled = pd.DataFrame(df_scaler, columns=features.columns)\n",
    "df_scaled\n",
    "\n",
    "\"\"\"Test Train Split With Imbalanced Dataset\"\"\"\n",
    "\n",
    "x = df_scaled.drop('TEY',axis=1)\n",
    "y = df_scaled[['TEY']]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting data into test data and train data\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=3)\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras\n",
    "keras. __version__\n",
    "\n",
    "model_data\n",
    "#assigning predictor variables to x and response variable to y\n",
    "x = model_data.drop('TEY', axis=1)\n",
    "y = model_data[[\"TEY\"]]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.20, random_state=42)\n",
    "\n",
    "scaler_train = StandardScaler()\n",
    "scaler_test = StandardScaler()\n",
    "\n",
    "x_train_scaled = scaler_train.fit_transform(x_train) # scaling train data -- predictor\n",
    "x_test_scaled  = scaler_test.fit_transform(x_test) # scaling test data -- predictor\n",
    "\n",
    "print(x_train_scaled.shape)\n",
    "print(x_test_scaled.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# since we have continuous ouput, AF is not required in the o/p layer\n",
    "model = Sequential()\n",
    "model.add( Dense( units = 50 , activation = 'relu' , kernel_initializer = 'normal', input_dim = 7)) # input layer\n",
    "model.add( Dense( units = 20 , activation = 'tanh' , kernel_initializer = 'normal' )) # hidden layer\n",
    "model.add( Dense( units = 1  , kernel_initializer = 'normal' )) # o/p layer\n",
    "\n",
    "model.compile(optimizer= \"adam\", loss=\"mse\", metrics= [\"mae\", \"mse\"])\n",
    "model.fit(x_train_scaled, y_train , batch_size=50, validation_split=0.3, epochs=100,  verbose=1)\n",
    "\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(model.history.history['mae'])\n",
    "plt.plot(model.history.history['mse'])\n",
    "plt.title(\"Model's Mean Absolute and Squared Errors\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.legend(['Mean Absulote Erroe', 'Mean Squared Error'],loc = 'upper left')\n",
    "plt.show()\n",
    "#summarize history for loss\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title('Model-loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean-Absolute-Error')\n",
    "plt.legend(['Training Error', 'Testing Error'],loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\"\"\"Predicting values from Model using same dataset\"\"\"\n",
    "\n",
    "# generating predictions for test data\n",
    "y_predict_test = model.predict(x_test_scaled)\n",
    "\n",
    "# creating table with test price & predicted price for test\n",
    "predictions_df = pd.DataFrame(x_test)\n",
    "predictions_df['Actual'] = y_test\n",
    "predictions_df['Predicted'] = y_predict_test\n",
    "print(predictions_df.shape)\n",
    "predictions_df.head(10)\n",
    "\n",
    "# Computing the absolute percent error\n",
    "APE=100*(abs(predictions_df['Actual']-predictions_df['Predicted'])/predictions_df['Actual'])\n",
    "print('The Accuracy for Test Data -- ANN model = ', 100-np.mean(APE))\n",
    "\n",
    "# adding absolute percent error to table\n",
    "predictions_df['APE %']=APE\n",
    "predictions_df.head()\n",
    "\n",
    "\"\"\"Residual Analysis\"\"\"\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.distplot(y_test-y_predict_test,bins=50)\n",
    "\n",
    "predictions_df['Error'] = (predictions_df['Actual'] - predictions_df['Predicted'])/(predictions_df['Actual'])\n",
    "predictions_df.reset_index(drop = True)\n",
    "\n",
    "#Residuals values  = y - yhat\n",
    "import statsmodels.api as smf\n",
    "smf.qqplot(predictions_df['Error'], line = 'q')\n",
    "plt.title('Normal Q-Q plot of residuals')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
